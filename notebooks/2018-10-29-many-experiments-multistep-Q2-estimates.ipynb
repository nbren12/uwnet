{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods for improving Q2 estiamtes\n",
    "\n",
    "We have seen that the multiples step training procedure introduces significant errors in the upper atmosphere. These result from the scheme trying to undo the errors it makes in early time steps. I believe this is mainly a result of the humidity in the upper atmosphere being forced to zero\n",
    "\n",
    "## Weight first prediction step more\n",
    "![](../models/116/q2_7-8.png)\n",
    "\n",
    "This helps somewhat but there are still large errors in the upper atmosphere. **All of the following techniques include this**\n",
    "\n",
    "## Multiply negative humidity by 100 in the loss function\n",
    "![](../models/119/q2_9-8.png)\n",
    "\n",
    "This appears to introduce positive bias everywhere, but it is still helpful.\n",
    "\n",
    "\n",
    "## Humidity loss is $q^{1/4}$\n",
    "![](../models/120/q2_3-8.png)\n",
    "\n",
    "Changing the humidity loss function to $(q^{1/4}-q_{true}^{.25}$ does reduce errors in the upper atmosphere, at the cost of errors in the lower atmosphere. Also, this solution blows up.\n",
    "\n",
    "## Predict $q_T f(x)$\n",
    "\n",
    "Computing the product rather than the sum helps ensure that there are fewer negative moisture points. Unforunately, the strong drying at the tropopause that we see in many other cases is also present. Perhaps, I should also compute FQT using log.\n",
    "\n",
    "![](../models/123/q2_9-8.png)\n",
    "\n",
    "## Adding random noise after every time step\n",
    "\n",
    "This can be viewed as a form of regularization. For now, I am adding normal random noise with a standard deviation of 5 [units]/day to both SLI and QT at all heights.\n",
    "\n",
    "![](../models/124/q2_9-8.png)\n",
    "\n",
    "The loss function is significantly worse when using this form of regularization, which is what we want I think.\n",
    "Ultimately, even with random noise the solutions seem to converge to the strong drying at the tropopause.\n",
    "\n",
    "### Increase the noise to 10\n",
    "\n",
    "![](../models/124/q2_4-8.png)\n",
    "\n",
    "### Random noise + q * f\n",
    "\n",
    "Let's try adding random noise along with the Q * F prediction.\n",
    "\n",
    "![](../models/126/q2_9-8.png)\n",
    "\n",
    "I think this is best approach I have tried so far.\n",
    "\n",
    "#### Try with seq_length=10\n",
    "\n",
    "Now, that I have tried it with seq_length=3, let's try it with seq_length=10.\n",
    "\n",
    "![](../models/127/q2_2-8.png)\n",
    "\n",
    "With longer prediction interval this method seems to underfit dramatically.\n",
    "\n",
    "#### Same as bove but smaller noise.\n",
    "RunID=129\n",
    "Make the noise 1.0...I can't make this stable for whatever reason. No decay with time.\n",
    "\n",
    "#### seq_length=10, noise size=1, no decay\n",
    "\n",
    "Very strong bias in upper atmos.. **no good**\n",
    "\n",
    "## Add penalty to loss function\n",
    "\n",
    "Also penalize the error in Q2 made between the schemes. There are a couple ways to do this:\n",
    "\n",
    "1. penalize the Q2 computed for the full predicted time series  $\\tilde{x}$ (this approach doesn't work well. No pictures unforunately!\n",
    "\n",
    "\n",
    "## Different loss decay schedule (Runid = 132)\n",
    "\n",
    "$loss = \\sum_i c_i loss_i $. $c = [10.0, r^i,...]$. The first point has ten times the loss of the next point, and then it decays at a constant rate.\n",
    "\n",
    "![](../models/132/q2_5-8.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sacred import get_run\n",
    "\n",
    "get_run(132)['config']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was run with a sequence length of 10. Let's see how a single column model simulation does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from uwnet.columns import single_column_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"../data/processed/training.nc\")\n",
    "\n",
    "def scm_plot(path):\n",
    "    model = torch.load(path)\n",
    "    location = ds.isel(x=slice(0,1), y=slice(32,33))\n",
    "    scm_data = single_column_simulation(model, location, interval=(0, 190))\n",
    "#     scm_data.QT.squeeze().T.plot.contourf()\n",
    "    return scm_data, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def water_budget_plots(path):\n",
    "    scm_data, model = scm_plot(path)\n",
    "    merged_pred_data = location.rename({'SLI': 'SLIOBS', 'QT': 'QTOBS'}).merge(scm_data, join='inner')\n",
    "    output = model.call_with_xr(merged_pred_data)\n",
    "\n",
    "    plt.figure()\n",
    "    output.QT.plot(x='time')\n",
    "    plt.title(\"FQTNN from NN-predicted OBS\")\n",
    "    output_truth = model.call_with_xr(location)\n",
    "\n",
    "    plt.figure()\n",
    "    output_truth.QT.plot(x='time')\n",
    "    plt.title(\"FQTNN from Truth\")\n",
    "    plt.xlim([100, 125])\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    (scm_data.QT * ds.layer_mass/1000).sum('z').plot()\n",
    "    (location.QT * ds.layer_mass/1000).sum('z').plot(label='observed')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_budget_plots(\"../models/132/4.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that there is a long term drift in the humidity in the single column simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decay loss with straight r^k\n",
    "\n",
    "This seems to worsen the results. The solutions oscillate between too much moistening and too much drying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_budget_plots(\"../models/133/5.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_budget_plots(\"../models/133/6.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_budget_plots(\"../models/133/8.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
