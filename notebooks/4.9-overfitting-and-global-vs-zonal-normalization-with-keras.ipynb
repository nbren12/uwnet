{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I train keras to predict the tendency of precipitable water on just the tropics. My hope is that the network can learn to conserve water pretty well. My goal is to overfit the data using the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('../data/processed/training.nc')\n",
    "\n",
    "mean = ds.mean(['time', 'x'])\n",
    "sig = np.abs(ds-mean).max(['x', 'time', 'z'])/3\n",
    "\n",
    "ds = ds.isel(x=[0, ], y=[30, 5], time=slice(0,20))\n",
    "\n",
    "# compute Q1 and Q2\n",
    "time = ds.time\n",
    "ds['Q2'] = ds.QT.diff('time')/(time[1]-time[0]) - 86400*(ds.FQT + ds.FQT.shift(time=-1))/2\n",
    "ds['Q1'] = ds.SLI.diff('time')/(time[1]-time[0]) - 86400*(ds.FSLI + ds.FSLI.shift(time=-1))/2\n",
    "\n",
    "ds['CQ2'] = (ds.Q2 * ds.layer_mass).sum('z')/1e4\n",
    "\n",
    "# drop the null dimensions\n",
    "ds = ds.dropna('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Q1.isel(x=0, y=0).plot(x='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.Q2.isel(x=0, y=0).plot(x='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.CQ2.isel(x=0, y=0).plot(x='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import random\n",
    "\n",
    "def grouplen(sequence, chunk_size):\n",
    "    return list(zip(*[iter(sequence)] * chunk_size))\n",
    "\n",
    "\n",
    "def index_and_stack(inds, x):\n",
    "    return np.stack(x[ind] for ind in inds)[:, :, np.newaxis, np.newaxis]\n",
    "\n",
    "\n",
    "def prepare_input_output_data(ds, input_fields, output_fields, height_dim='z'):\n",
    "    \n",
    "    def prepvar(x):\n",
    "        if height_dim in x.dims:\n",
    "            return x.values\n",
    "        else:\n",
    "            return np.expand_dims(x.values, -3)\n",
    "            \n",
    "            \n",
    "            \n",
    "    return [[prepvar(ds[key]) for key in field_list]\n",
    "            for field_list in [input_fields, output_fields]]\n",
    "\n",
    "\n",
    "\n",
    "class batch_generator(object):\n",
    "    def __init__(self, ds, in_fields, out_fields, batch_size=None, shuffle=True):\n",
    "        ins, outs = prepare_input_output_data(ds, in_fields, out_fields)\n",
    "\n",
    "        (t, z, y, x) = ins[0].shape\n",
    "\n",
    "        inds = [(i,slice(None), j, k) for i,j,k in product(range(t), range(y), range(x))]\n",
    "\n",
    "        if shuffle:\n",
    "            random.shuffle(inds)\n",
    "\n",
    "        if batch_size is None:\n",
    "            self.batch_indices = [inds]\n",
    "        else:\n",
    "            self.batch_indices = grouplen(inds, batch_size)\n",
    "        self.ins = ins\n",
    "        self.outs = outs\n",
    "        \n",
    "        self.cur_batch = 0\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.batch_indices)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        idxs = self.batch_indices[self.cur_batch]\n",
    "        self.cur_batch = (self.cur_batch + 1) % len(self)\n",
    "        return [index_and_stack(idxs, x) for x in self.ins], [index_and_stack(idxs, y) for y in self.outs]\n",
    "\n",
    "        \n",
    "def normalize_dataset(ds):\n",
    "    dims = [dim for dim in ['x', 'y', 'time'] if dim in ds.dims]\n",
    "    mean = ds.mean(dims)\n",
    "    sig = np.abs(ds-mean).max()/3\n",
    "    \n",
    "    ds_normalized = (ds- mean)/sig\n",
    "    return ds_normalized   \n",
    "    \n",
    "\n",
    "in_fields, out_fields = ['QT', 'SLI', 'LHF', 'SHF', 'SOLIN'], ['Q2']\n",
    "ins, outs= prepare_input_output_data(ds, in_fields, out_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import absolute_import\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messing around with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(shape=(34, None, None))\n",
    "p = Permute([2, 3, 1])(i)\n",
    "o = Dense(512)(p)\n",
    "\n",
    "mod_simple = Model(inputs=[i], outputs=[o])\n",
    "mod_simple.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for k, (x, y) in enumerate(batch_generator(ds, in_fields, out_fields)):\n",
    "    break\n",
    "\n",
    "    \n",
    "def get_model(n):\n",
    "    # assume inputs have shape (*, z, y, x)\n",
    "    inputs_keras = [Input((xx.shape[1], None, None), name=name) for name, xx in zip(in_fields, x)]\n",
    "    output_shapes = [yy.shape[1] for yy in y]\n",
    "\n",
    "    catted = Concatenate(axis=-3)(inputs_keras)\n",
    "    perm = Permute([2,3,1])(catted)\n",
    "    layer1 = Dense(n, activation='relu')(perm)\n",
    "    # layer2 = Dense(activation='relu')(layer1)\n",
    "    outputs = [Permute([3, 1, 2], name=name)(Dense(n)(layer1)) \n",
    "               for name, n in zip(out_fields, output_shapes)]\n",
    "\n",
    "    return Model(inputs_keras, outputs)\n",
    "\n",
    "\n",
    "def fit_model(ds_normalized, model):\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=Adam(lr=.01),\n",
    "                  metrics=['accuracy'])\n",
    "    gen = batch_generator(ds_normalized, in_fields, out_fields, batch_size=None)\n",
    "    history = model.fit_generator(gen, steps_per_epoch=len(gen), epochs=5000, verbose=0)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def plot_model(ds_normalized, model):\n",
    "    x, y = prepare_input_output_data(ds_normalized, in_fields, out_fields)\n",
    "    outs = {name: val for name, val in zip(model.output_names, model.predict(x))}\n",
    "\n",
    "    cq2 = model.predict(x).squeeze()\n",
    "\n",
    "    dims = ['time', 'z', 'y']\n",
    "    coords = {key: ds_normalized.coords[key] for key in dims}\n",
    "\n",
    "    cq2 = xr.DataArray(cq2, dims=dims, coords=coords)\n",
    "\n",
    "    # ds_normalized.Q2.isel(x=0,y=0).plot()\n",
    "    # plt.figure()\n",
    "    # (cq2-ds_normalized.Q2).plot(x='time')\n",
    "\n",
    "    from matplotlib.colors import LogNorm\n",
    "    x,y,z = xr.broadcast(cq2, ds_normalized.Q2, cq2.z)\n",
    "    plt.scatter(x, y, c=z, norm=LogNorm())\n",
    "    plt.colorbar()\n",
    "    \n",
    "    \n",
    "def fit_and_plot(ds, n=256):\n",
    "    model = get_model(n)\n",
    "    history= fit_model(ds, model)\n",
    "    plt.figure()\n",
    "    plot_model(ds, model)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use two normalization strategies. By latitude and global. In by latitude, the data are first normalized by mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize by pre-computed mean/sig\n",
    "ds_normalized = ds.copy()\n",
    "for key in in_fields:\n",
    "    ds_normalized[key] = (ds[key]-mean[key].sel(y=ds.y))/sig[key].sel(y=ds.y)\n",
    "\n",
    "# normalize by mean accross meridional slices\n",
    "ds_normalized_global = ds.copy()\n",
    "for key in in_fields:\n",
    "    ds_normalized_global[key] = normalize_dataset(ds[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap = hv.HoloMap(kdims=['n', 'norm'])\n",
    "for n in [16, 32, 64]:\n",
    "    history = fit_and_plot(ds_normalized, n)\n",
    "    hmap[(n, 'ByLat')] = hv.Curve(history.history['loss'])\n",
    "    \n",
    "    history = fit_and_plot(ds_normalized_global, n)\n",
    "    hmap[(n, 'Global')] = hv.Curve(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve[width=400, height=int(400/1.61)]\n",
    "hmap.overlay(\"norm\").redim.range(y=(0,.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that normalizing the input data by zonal means significantly improves the training procedure. For low number of hidden nodes it seems that the Global normalization procedure cannot overfit the small number of training points. This suggests it will be very challenging to sufficiently train the network on a full dataset. Therefore, we should **normalize the data by the zonal mean and scaling**. This is not a problem for now, but in the future, we can perhaps make the normalization depend on the state for instance be subtracting a moist adiatic profile or something."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
