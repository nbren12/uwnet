{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import open_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nudging = open_data('nudge')\n",
    "training = open_data('training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nudge_3d = xr.open_mfdataset(nudging.files_3d, drop_variables=['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3d = training.sel(time=nudge_3d.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3d.QT[100,10].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nudge_3d.QT[100,10].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_dims_and_concat_feats(ds, variables, sample_dims=('x', 'y', 'time'), feature_dims=('z')):\n",
    "    \"\"\"Convert certain variables of a data frame into 2D numpy arrays\"\"\"\n",
    "    \n",
    "    # convert tuple args to lists\n",
    "    sample_dims = list(sample_dims)\n",
    "    feature_dims = list(feature_dims)\n",
    "    \n",
    "    flat_arrays = []\n",
    "    for name in variables:\n",
    "        da = ds[name]\n",
    "        # for two-d variables insert a singleton \"z\" dimension\n",
    "        if 'z' not in da.dims:\n",
    "            da = da.expand_dims('z')\n",
    "        stacked_da = da.stack(samples=sample_dims, features=feature_dims)\n",
    "        # make sure the rows are samples and columns are features\n",
    "        tranposed_da = stacked_da.transpose('samples', 'features')\n",
    "        flat_arrays.append(tranposed_da.values)\n",
    "\n",
    "    # concatenate along the final dimension\n",
    "    # also outuput coord info for later use\n",
    "\n",
    "    return np.concatenate(flat_arrays, axis=1), stacked_da.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = -10\n",
    "\n",
    "x,_ = stack_dims_and_concat_feats(nudge_3d.isel(time=t), ['QT'], sample_dims=['x', 'y'])\n",
    "y,_ = stack_dims_and_concat_feats(train_3d.isel(time=t), ['QT'], sample_dims=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,10], y[:,10], alpha=.02)\n",
    "plt.plot([0, 10],[0,10], 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformedTargetRegressor(\n",
    "    regressor=make_pipeline(StandardScaler(), Lasso(.1)),\n",
    "    transformer=StandardScaler())\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y[:,10], y_pred[:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = model.regressor_.named_steps['lasso']\n",
    "plt.pcolormesh(lasso.coef_)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y[:,10], x[:,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model of noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([x, y], axis=1)\n",
    "cov = np.cov(X.T)\n",
    "precision = np.linalg.pinv(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(np.linalg.inv(precision[:22,:22]))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the noise covariance I will have to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov((x-y).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(cov)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.linalg.cholesky(cov)\n",
    "n = Q.shape[0]\n",
    "\n",
    "z = Q @ np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare to old distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pert = x +  np.random.randn(x.shape[0], n) @ Q.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution of QV at level 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x[:,10], 100);\n",
    "# plt.hist(x_pert[:,15], 100, alpha=.4);\n",
    "plt.hist(y[:,10], 100, alpha=.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x[:,10], 100);\n",
    "\n",
    "plt.hist(x_pert[:, 10], 100, alpha=.4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of PW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uwnet.thermo import layer_mass_from_p\n",
    "\n",
    "dm = layer_mass_from_p(open_data('pressure')).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x.dot(dm), 100);\n",
    "plt.hist(x_pert.dot(dm), 100, alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x.dot(dm), 100);\n",
    "plt.hist(y.dot(dm), 100, alpha=.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding gaussian noise helps somewhat, but the right tail of PW is still much fatter with the true data. I think we will need a better model of the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nudge_3d.W.isel(y=32).mean(['x', 'time']).plot(label='Nudge')\n",
    "train_3d.W.isel(y=32).mean(['x', 'time']).plot(label='Training')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average vertical velocity at the equator in the nudged simulation is so much weaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_nudge = x.dot(dm)/1000\n",
    "pw_true = y.dot(dm)/1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((pw_true - pw_nudge), 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution does seems pretty close to guassian, although it does have fatter tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pert = np.random.randn(x.shape[0], n) @ Q.T\n",
    "pert_pw = pert.dot(dm)/1000\n",
    "plt.hist(pert_pw, 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this actually seems like a prety good fit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
